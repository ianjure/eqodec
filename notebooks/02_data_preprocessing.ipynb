{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9d98f0-d038-40cf-b960-dd70dac073ef",
   "metadata": {},
   "source": [
    "### **Notebook Objectives**\n",
    "\n",
    "1. **Subset Data:** Get only 1% of the original dataset for efficiency.\n",
    "2. **Create Splits:** Deterministically split data into Training (90%) and Validation (10%) sets.\n",
    "3. **Index Splits:** Save `train_split.json` and `val_split.json` so the training notebook can load them instantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106658a3-659b-4c32-a9b7-59ad42167223",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb8890e-6d91-4f62-a843-4d6b95b5d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5344210e-0847-4fef-96a9-c1b7d9987428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(raw_root, processed_root, sample_ratio, \n",
    "                    train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Scans raw data, creates a random subset, and splits into train/val/test.\n",
    "\n",
    "    Args:\n",
    "        sample_ratio (float): Percentage of total data to keep.\n",
    "        train_ratio, val_ratio, test_ratio: Ratios for splitting.\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Scanning {raw_root} ...\")\n",
    "\n",
    "    valid_sequences = []\n",
    "\n",
    "    if not os.path.exists(raw_root):\n",
    "        print(\"Raw data not found.\")\n",
    "        return\n",
    "\n",
    "    # Scan directories\n",
    "    for root, dirs, files in os.walk(raw_root):\n",
    "        if \"im1.png\" in files and \"im7.png\" in files:\n",
    "            rel_path = os.path.relpath(root, raw_root)\n",
    "            valid_sequences.append(rel_path)\n",
    "\n",
    "    total_found = len(valid_sequences)\n",
    "    print(f\"[INFO] Total sequences found: {total_found}\")\n",
    "\n",
    "    # Global shuffle\n",
    "    random.seed(42)\n",
    "    random.shuffle(valid_sequences)\n",
    "\n",
    "    # Apply subsetting\n",
    "    subset_size = int(total_found * sample_ratio)\n",
    "    subset_sequences = valid_sequences[:subset_size]\n",
    "    print(f\"\\nSUBSETTING APPLIED\")\n",
    "    print(f\"[INFO] Keeping {subset_size} sequences ({sample_ratio*100}%)\")\n",
    "\n",
    "    # Compute split indices\n",
    "    n = len(subset_sequences)\n",
    "    train_end = int(n * train_ratio)\n",
    "    val_end = train_end + int(n * val_ratio)\n",
    "\n",
    "    # Split\n",
    "    train_seqs = subset_sequences[:train_end]\n",
    "    val_seqs = subset_sequences[train_end:val_end]\n",
    "    test_seqs = subset_sequences[val_end:]\n",
    "\n",
    "    # Save lists\n",
    "    os.makedirs(processed_root, exist_ok=True)\n",
    "\n",
    "    train_path = os.path.join(processed_root, \"train_split.json\")\n",
    "    val_path = os.path.join(processed_root, \"val_split.json\")\n",
    "    test_path = os.path.join(processed_root, \"test_split.json\")\n",
    "\n",
    "    with open(train_path, 'w') as f:\n",
    "        json.dump(train_seqs, f)\n",
    "\n",
    "    with open(val_path, 'w') as f:\n",
    "        json.dump(val_seqs, f)\n",
    "\n",
    "    with open(test_path, 'w') as f:\n",
    "        json.dump(test_seqs, f)\n",
    "\n",
    "    print(f\"\\nSPLITTING COMPLETE\")\n",
    "    print(f\"[INFO] Train: {len(train_seqs)} items (Saved to {train_path})\")\n",
    "    print(f\"[INFO] Val:   {len(val_seqs)} items (Saved to {val_path})\")\n",
    "    print(f\"[INFO] Test:  {len(test_seqs)} items (Saved to {test_path})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44348e5-8b28-4464-93a9-77ee53227779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Scanning ../data/raw/vimeo/sequences ...\n",
      "[INFO] Total sequences found: 91701\n",
      "\n",
      "SUBSETTING APPLIED\n",
      "[INFO] Keeping 917 sequences (1.0%)\n",
      "\n",
      "SPLITTING COMPLETE\n",
      "[INFO] Train: 733 items (Saved to ../data/processed\\train_split.json)\n",
      "[INFO] Val:   91 items (Saved to ../data/processed\\val_split.json)\n",
      "[INFO] Test:  93 items (Saved to ../data/processed\\test_split.json)\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(\n",
    "    \"../data/raw/vimeo/sequences\",\n",
    "    \"../data/processed\",\n",
    "    sample_ratio=0.01\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eqodec",
   "language": "python",
   "name": "eqodec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
